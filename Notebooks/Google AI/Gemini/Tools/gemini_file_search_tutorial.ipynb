{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boskein/Awesome-Onion-Links/blob/master/Notebooks/Google%20AI/Gemini/Tools/gemini_file_search_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r9aqk562Mdr"
      },
      "source": [
        "# üöÄ Tutorial Completo: Gemini File Search - Sistema RAG Profesional\n",
        "\n",
        "## üìö √çndice\n",
        "\n",
        "1. [Introducci√≥n y Setup](#1-introducci√≥n)\n",
        "2. [Crear File Search Store](#2-crear-file-search-store)\n",
        "3. [Subir y Indexar Documentos](#3-subir-documentos)\n",
        "4. [Realizar B√∫squedas B√°sicas](#4-b√∫squedas-b√°sicas)\n",
        "5. [Obtener Citaciones](#5-citaciones)\n",
        "6. [Metadata Filtering Avanzado](#6-metadata-filtering)\n",
        "7. [Gesti√≥n de Stores](#7-gesti√≥n-stores)\n",
        "8. [Chunking Personalizado](#8-chunking-personalizado)\n",
        "9. [Mejores Pr√°cticas](#9-mejores-pr√°cticas)\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ÑπÔ∏è Acerca de este Tutorial\n",
        "\n",
        "**Nivel:** Intermedio  \n",
        "**Duraci√≥n estimada:** 30-40 minutos  \n",
        "**Requisitos previos:**\n",
        "- Python 3.9+\n",
        "- Conocimientos b√°sicos de Python\n",
        "- API Key de Google AI Studio\n",
        "\n",
        "**¬øQu√© aprender√°s?**\n",
        "- Implementar un sistema RAG completo sin gestionar infraestructura\n",
        "- Indexar documentos de m√∫ltiples formatos\n",
        "- Realizar b√∫squedas sem√°nticas avanzadas\n",
        "- Filtrar resultados con metadata\n",
        "- Obtener citaciones autom√°ticas\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOQJacZY2Mdw"
      },
      "source": [
        "## 1. üîß Introducci√≥n y Setup\n",
        "\n",
        "### ¬øQu√© es File Search?\n",
        "\n",
        "File Search es un sistema RAG (Retrieval Augmented Generation) completamente gestionado por Google que te permite:\n",
        "\n",
        "- ‚úÖ **Subir documentos** de m√∫ltiples formatos (PDF, DOCX, TXT, JSON, c√≥digo, etc.)\n",
        "- ‚úÖ **Indexaci√≥n autom√°tica** con chunking inteligente y embeddings de √∫ltima generaci√≥n\n",
        "- ‚úÖ **B√∫squeda sem√°ntica** que entiende significado, no solo palabras clave\n",
        "- ‚úÖ **Citaciones autom√°ticas** para verificabilidad\n",
        "- ‚úÖ **Sin infraestructura** - no necesitas Pinecone, Chroma, ni gestionar bases vectoriales\n",
        "\n",
        "### üí∞ Precios\n",
        "\n",
        "- **Storage:** GRATIS ‚ú®\n",
        "- **Embeddings en indexaci√≥n:** $0.15 por 1M tokens (una sola vez al subir)\n",
        "- **Embeddings en b√∫squeda:** GRATIS\n",
        "- **Tokens recuperados:** Se cobran como context tokens del modelo\n",
        "\n",
        "### üì¶ Instalaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3wLQH3OY2Mdy"
      },
      "outputs": [],
      "source": [
        "# Instalar la librer√≠a de Google Generative AI\n",
        "!pip install google-genai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2EbANLF2Md1"
      },
      "source": [
        "### üîë Configurar API Key\n",
        "\n",
        "**Opci√≥n 1: Variable de entorno (recomendado para producci√≥n)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yUPM20r2Md2",
        "outputId": "3c43508c-d587-491a-abfe-f20457b0afe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Key configurada\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Si no tienes la API key en variables de entorno, ingr√©sala aqu√≠\n",
        "if 'GOOGLE_API_KEY' not in os.environ:\n",
        "    os.environ['GOOGLE_API_KEY'] = getpass('Ingresa tu API Key de Google AI Studio: ')\n",
        "\n",
        "API_KEY = os.environ['GOOGLE_API_KEY']\n",
        "print(\"‚úÖ API Key configurada\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oCEulwN2Md3"
      },
      "source": [
        "**Opci√≥n 2: Directamente en c√≥digo (solo para desarrollo)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCclt77-2Md4"
      },
      "outputs": [],
      "source": [
        "# ‚ö†Ô∏è NO USES ESTO EN PRODUCCI√ìN - Solo para testing local\n",
        "# API_KEY = 'TU_API_KEY_AQUI'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Opci√≥n 3: Secretos (Solo para google Colab)**"
      ],
      "metadata": {
        "id": "FIDxzUZc2cMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "MopVXTv22trw",
        "outputId": "d38f35ee-58a6-497c-b4fe-3d03aa511389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret GEMINI_API_KEY does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4184463372.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mAPI_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GEMINI_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret GEMINI_API_KEY does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhjPKmOI2Md4"
      },
      "source": [
        "### üìö Imports necesarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP4aLfkK2Md5",
        "outputId": "e5d25f60-a37e-4778-e445-dce9782fc0bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cliente inicializado correctamente\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import time\n",
        "from typing import List, Dict, Optional\n",
        "import json\n",
        "\n",
        "# Inicializar el cliente de Gemini\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "print(\"‚úÖ Cliente inicializado correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDS52_ds2Md6"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. üì¶ Crear File Search Store\n",
        "\n",
        "Un **File Search Store** es un contenedor para tus documentos indexados. Pi√©nsalo como una base de datos especializada.\n",
        "\n",
        "### Mejores pr√°cticas:\n",
        "- üóÇÔ∏è Crea stores separados por tipo de contenido (ej: docs p√∫blicas vs internas)\n",
        "- üìù Usa `display_name` descriptivo para identificar f√°cilmente\n",
        "- üéØ Mant√©n cada store bajo 20GB para latencias √≥ptimas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0esdEJ8Z2Md7"
      },
      "outputs": [],
      "source": [
        "def create_file_search_store(display_name: str) -> genai.types.FileSearchStore:\n",
        "    \"\"\"\n",
        "    Crea un nuevo File Search Store.\n",
        "\n",
        "    Args:\n",
        "        display_name: Nombre descriptivo para identificar el store\n",
        "\n",
        "    Returns:\n",
        "        FileSearchStore object con informaci√≥n del store creado\n",
        "    \"\"\"\n",
        "    store = client.file_search_stores.create(\n",
        "        config={'display_name': display_name}\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ Store creado exitosamente\")\n",
        "    print(f\"   ‚Ä¢ Nombre: {store.name}\")\n",
        "    print(f\"   ‚Ä¢ Display Name: {display_name}\")\n",
        "\n",
        "    return store"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Crear nuestro primer store\n",
        "store = create_file_search_store(\"reporte_1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgE9GGSpEMsl",
        "outputId": "86379d8c-f14f-4182-bb0c-88700f65d708"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Store creado exitosamente\n",
            "   ‚Ä¢ Nombre: fileSearchStores/reporte1-eg6nnoq7rwb7\n",
            "   ‚Ä¢ Display Name: reporte_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Crear nuestro primer store\n",
        "store_script = create_file_search_store(\"reporte_2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTKe_ZWkEP3B",
        "outputId": "ccfe5901-28b1-49ca-cba1-59ae09873df2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Store creado exitosamente\n",
            "   ‚Ä¢ Nombre: fileSearchStores/reporte2-fxyfq9pnwsow\n",
            "   ‚Ä¢ Display Name: reporte_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MgA5cqP2Md8"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. üìÑ Subir y Indexar Documentos\n",
        "\n",
        "### Formatos soportados:\n",
        "- üìë Documentos: PDF, DOCX, TXT, MD, RTF\n",
        "- üíª C√≥digo: Python, JavaScript, Java, C++, Go, Rust, y m√°s\n",
        "- üìä Datos: JSON, CSV, XML\n",
        "- üåê Web: HTML\n",
        "\n",
        "### M√©todo 1: Upload directo (recomendado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PJXFLTwE2Md9"
      },
      "outputs": [],
      "source": [
        "def upload_file_to_store(\n",
        "    file_path: str,\n",
        "    store_name: str,\n",
        "    display_name: Optional[str] = None,\n",
        "    custom_metadata: Optional[List[Dict]] = None\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Sube e indexa un archivo directamente en un File Search Store.\n",
        "\n",
        "    Args:\n",
        "        file_path: Ruta local al archivo\n",
        "        store_name: Nombre del store (ej: 'fileSearchStores/abc123')\n",
        "        display_name: Nombre para identificar el archivo (opcional)\n",
        "        custom_metadata: Lista de metadatos personalizados (opcional)\n",
        "\n",
        "    Returns:\n",
        "        bool: True si la indexaci√≥n fue exitosa\n",
        "    \"\"\"\n",
        "    try:\n",
        "        config = {}\n",
        "        if display_name:\n",
        "            config['display_name'] = display_name\n",
        "        if custom_metadata:\n",
        "            config['custom_metadata'] = custom_metadata\n",
        "\n",
        "        print(f\"üì§ Subiendo: {file_path}...\")\n",
        "\n",
        "        # Iniciar la operaci√≥n de upload\n",
        "        operation = client.file_search_stores.upload_to_file_search_store(\n",
        "            file=file_path,\n",
        "            file_search_store_name=store_name,\n",
        "            config=config if config else None\n",
        "        )\n",
        "\n",
        "        # Esperar a que la indexaci√≥n complete\n",
        "        print(f\"‚è≥ Indexando (esto puede tomar algunos segundos)...\")\n",
        "        while not operation.done:\n",
        "            time.sleep(5)\n",
        "            operation = client.operations.get(operation)\n",
        "\n",
        "        print(f\"‚úÖ Archivo indexado: {display_name or file_path}\\n\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error indexando {file_path}: {str(e)}\\n\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A9saVgD2Md-"
      },
      "source": [
        "### Ejemplo: Crear un documento de prueba y subirlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LFecfhF2MeA",
        "outputId": "b5b8f735-0509-41cb-c13e-70fd909baeeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Subiendo: /content/WEF_Future_of_Jobs_Report_2025.pdf...\n",
            "‚è≥ Indexando (esto puede tomar algunos segundos)...\n",
            "‚úÖ Archivo indexado: Reporte\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Subir el documento\n",
        "upload_file_to_store(\n",
        "    file_path='/content/WEF_Future_of_Jobs_Report_2025.pdf',\n",
        "    store_name=store.name,\n",
        "    display_name='Reporte',\n",
        "    custom_metadata=[\n",
        "        {'key': 'tipo', 'string_value': 'gu√≠a'},\n",
        "        {'key': 'idioma', 'string_value': 'english'},\n",
        "        {'key': 'version', 'numeric_value': 1}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subir el documento\n",
        "upload_file_to_store(\n",
        "    file_path='/content/informe-colombia.pdf',\n",
        "    store_name=store_script.name,\n",
        "    display_name='Informe Colombia',\n",
        "    custom_metadata=[\n",
        "        {'key': 'tipo', 'string_value': 'script'},\n",
        "        {'key': 'version', 'numeric_value': 2}\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxhEJ0IbIJ-E",
        "outputId": "c656d435-9f08-4698-d1e4-1543d27ba134"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Subiendo: /content/informe-colombia.pdf...\n",
            "‚è≥ Indexando (esto puede tomar algunos segundos)...\n",
            "‚úÖ Archivo indexado: Informe Colombia\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUXqKIQr2MeA"
      },
      "source": [
        "### Subir m√∫ltiples archivos de forma eficiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_dh61hwq2MeB"
      },
      "outputs": [],
      "source": [
        "def batch_upload_files(\n",
        "    file_paths: List[str],\n",
        "    store_name: str,\n",
        "    metadata_generator: Optional[callable] = None\n",
        ") -> Dict[str, bool]:\n",
        "    \"\"\"\n",
        "    Sube m√∫ltiples archivos de forma secuencial.\n",
        "\n",
        "    Args:\n",
        "        file_paths: Lista de rutas a archivos\n",
        "        store_name: Nombre del store\n",
        "        metadata_generator: Funci√≥n que genera metadata para cada archivo\n",
        "\n",
        "    Returns:\n",
        "        Dict con el resultado de cada upload (filename: success_bool)\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    print(f\"üì¶ Iniciando batch upload de {len(file_paths)} archivos...\\n\")\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        metadata = metadata_generator(file_path) if metadata_generator else None\n",
        "\n",
        "        success = upload_file_to_store(\n",
        "            file_path=file_path,\n",
        "            store_name=store_name,\n",
        "            display_name=file_path,\n",
        "            custom_metadata=metadata\n",
        "        )\n",
        "\n",
        "        results[file_path] = success\n",
        "\n",
        "    # Resumen\n",
        "    successful = sum(1 for v in results.values() if v)\n",
        "    print(f\"\\nüìä Resumen: {successful}/{len(file_paths)} archivos indexados exitosamente\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Ejemplo: crear y subir varios documentos\n",
        "# (Descomenta si quieres probar con m√∫ltiples archivos)\n",
        "\n",
        "# archivos = ['doc1.txt', 'doc2.txt', 'doc3.txt']\n",
        "# results = batch_upload_files(archivos, store.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Rea0eOi2MeC"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. üîç Realizar B√∫squedas B√°sicas\n",
        "\n",
        "Ahora que tenemos documentos indexados, podemos hacer consultas en lenguaje natural.\n",
        "\n",
        "### C√≥mo funciona:\n",
        "1. Tu consulta se convierte en un embedding\n",
        "2. Se buscan los chunks m√°s similares sem√°nticamente\n",
        "3. Los chunks relevantes se inyectan en el contexto del modelo\n",
        "4. El modelo genera una respuesta fundamentada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "upJiod2t2MeD"
      },
      "outputs": [],
      "source": [
        "def search_file_store(\n",
        "    query: str,\n",
        "    store_names: List[str],\n",
        "    model: str = 'gemini-2.5-flash',\n",
        "    metadata_filter: Optional[str] = None\n",
        ") -> genai.types.GenerateContentResponse:\n",
        "    \"\"\"\n",
        "    Realiza una b√∫squeda en uno o m√°s File Search Stores.\n",
        "\n",
        "    Args:\n",
        "        query: Pregunta o consulta en lenguaje natural\n",
        "        store_names: Lista de stores donde buscar\n",
        "        model: Modelo de Gemini a usar (2.5-flash o 2.5-pro)\n",
        "        metadata_filter: Filtro opcional de metadata\n",
        "\n",
        "    Returns:\n",
        "        Respuesta del modelo con el contenido generado\n",
        "    \"\"\"\n",
        "    # Configurar la herramienta de File Search\n",
        "    file_search_config = types.FileSearch(\n",
        "        file_search_store_names=store_names\n",
        "    )\n",
        "\n",
        "    if metadata_filter:\n",
        "        file_search_config.metadata_filter = metadata_filter\n",
        "\n",
        "    # Hacer la consulta\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=query,\n",
        "        config=types.GenerateContentConfig(\n",
        "            tools=[\n",
        "                types.Tool(\n",
        "                    file_search=file_search_config\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooleTCLy2MeF"
      },
      "source": [
        "[texto del enlace](https://)### Ejemplo: Consultas b√°sicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo52Tasr2MeG",
        "outputId": "faf89e54-def2-4d0e-96e3-ec34069a5f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùì Pregunta: ¬øCu√°l es el costo de usar File Search?\n",
            "\n",
            "üí¨ Respuesta:\n",
            "According to the EHS Maturity Curve, 67.1% of organizations are in Stage 2, which is categorized as \"Operational.\" In this stage, organizations focus on workforce engagement and visibility, utilizing point solutions for core areas, though some processes may still be paper and spreadsheet-based. This stage also involves limited digitization.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Consulta 1: Precio\n",
        "print(\"‚ùì Pregunta: ¬øCu√°l es el costo de usar File Search?\\n\")\n",
        "\n",
        "response = search_file_store(\n",
        "    query=\"EHS Maturity curve percentage in stage 2\",\n",
        "    store_names=[store_script.name]\n",
        ")\n",
        "\n",
        "print(f\"üí¨ Respuesta:\\n{response.text}\\n\")\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7BpwmtM2MeG",
        "outputId": "fc410508-f14c-48cb-b686-7299c9c9a62e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùì Pregunta: ¬øQu√© formatos de archivo soporta?\n",
            "\n",
            "üí¨ Respuesta:\n",
            "Lo siento, no pude encontrar el valor global del software EHS para 2024-2025 en los documentos proporcionados. Los informes se centran en tendencias econ√≥micas, perspectivas laborales, habilidades y otros aspectos, pero no en el tama√±o del mercado del software EHS.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Consulta 2: Caracter√≠sticas\n",
        "print(\"‚ùì Pregunta: ¬øQu√© formatos de archivo soporta?\\n\")\n",
        "\n",
        "response = search_file_store(\n",
        "    query=\"¬øValor global EHS SW 2024-25?\",\n",
        "    store_names=[store.name]\n",
        ")\n",
        "\n",
        "print(f\"üí¨ Respuesta:\\n{response.text}\\n\")\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEkL7JO62MeH",
        "outputId": "39a30f01-c749-4750-ace5-f0ec85b45fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùì Pregunta: ¬øPara qu√© casos de uso se recomienda?\n",
            "\n",
            "üí¨ Respuesta:\n",
            "El software de Environment, Health & Safety (EHS) est√° evolucionando para incorporar nuevas tendencias y prioridades. Aunque la informaci√≥n proporcionada no detalla una transici√≥n espec√≠fica \"de X a Y\" para el software EHS, se pueden inferir varias direcciones clave basadas en las tendencias generales del mercado laboral y las estrategias empresariales:\n",
            "\n",
            "*   **De la gesti√≥n reactiva a la proactiva y basada en datos:** Se espera una creciente demanda de habilidades en IA y big data, as√≠ como un enfoque en el pensamiento anal√≠tico. Esto sugiere que el software EHS se mover√° hacia soluciones que utilicen grandes vol√∫menes de datos para an√°lisis predictivos y una gesti√≥n m√°s proactiva de la seguridad y el medio ambiente, en lugar de solo registrar incidentes pasados.\n",
            "*   **Mayor integraci√≥n con la sostenibilidad y la gesti√≥n ambiental:** Las empresas est√°n priorizando la administraci√≥n ambiental y la reducci√≥n de emisiones de carbono. Esto implica que el software EHS se expandir√° para incluir herramientas m√°s sofisticadas para el seguimiento del impacto ambiental, la gesti√≥n de la sostenibilidad y el cumplimiento de las normativas relacionadas con el cambio clim√°tico.\n",
            "*   **Enfoque en el bienestar y la seguridad de los empleados:** Las empresas planean priorizar la salud y el bienestar de los empleados (79%) y la seguridad en el lugar de trabajo (53%). El software EHS probablemente incorporar√° funciones mejoradas para gestionar estos aspectos, posiblemente incluyendo m√≥dulos para el bienestar, la salud mental y la prevenci√≥n de riesgos laborales de manera m√°s integral.\n",
            "*   **Adopci√≥n de tecnolog√≠as emergentes como la IA y el aprendizaje autom√°tico:** Especialistas en IA y aprendizaje autom√°tico, junto con cient√≠ficos de datos, son roles en crecimiento. Esto indica que el software EHS integrar√° m√°s capacidades de IA para automatizaci√≥n de tareas, an√°lisis de riesgos y toma de decisiones mejorada.\n",
            "*   **Mayor digitalizaci√≥n y automatizaci√≥n de procesos:** Aunque la digitalizaci√≥n es un factor menos central para algunas industrias en comparaci√≥n con la experiencia humana, sigue siendo relevante. Las empresas est√°n acelerando la automatizaci√≥n de procesos y tareas, lo que sugiere que el software EHS se volver√° m√°s digitalizado y automatizado para optimizar la eficiencia y la precisi√≥n.\n",
            "\n",
            "En resumen, el software EHS est√° en transici√≥n hacia soluciones m√°s inteligentes, integradas y predictivas que abordan un espectro m√°s amplio de preocupaciones ambientales, de salud y seguridad, y que se apoyan en tecnolog√≠as avanzadas como la IA y el big data.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Consulta 3: Casos de uso\n",
        "print(\"‚ùì Pregunta: ¬øPara qu√© casos de uso se recomienda?\\n\")\n",
        "\n",
        "response = search_file_store(\n",
        "    query=\"El software de Environment, Health & Safety (EHS) pasar√° de \",\n",
        "    store_names=[store.name]\n",
        ")\n",
        "\n",
        "print(f\"üí¨ Respuesta:\\n{response.text}\\n\")\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consulta 4: Casos de uso\n",
        "print(\"‚ùì Pregunta: Cual es el nombre del ganso?\\n\")\n",
        "\n",
        "response = search_file_store(\n",
        "    query=\"Cual es el nombre del ganso?\",\n",
        "    store_names=[store_script.name]\n",
        ")\n",
        "\n",
        "print(f\"üí¨ Respuesta:\\n{response.text}\\n\")\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG_4VOrjI2Ue",
        "outputId": "8067d5da-b606-4778-d67d-bb5300adda04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùì Pregunta: Cual es el nombre del ganso?\n",
            "\n",
            "üí¨ Respuesta:\n",
            "El nombre del ganso es Brightbill. Inicialmente, Roz lo nombr√≥ \"Gosling zero-zero-zero-one\", pero m√°s tarde le dio el nombre de Brightbill.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consulta 4: Casos de uso\n",
        "print(\"‚ùì Pregunta: Quien es Fink, responde en espa√±ol?\\n\")\n",
        "\n",
        "response = search_file_store(\n",
        "    query=\"Quien es Fink, responde en espa√±ol?\",\n",
        "    store_names=[store_script.name]\n",
        ")\n",
        "\n",
        "print(f\"üí¨ Respuesta:\\n{response.text}\\n\")\n",
        "print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsgWeDlCJK2Z",
        "outputId": "3d33aae5-b4cc-4608-a048-2e20d9f50959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùì Pregunta: Quien es Fink, responde en espa√±ol?\n",
            "\n",
            "üí¨ Respuesta:\n",
            "Fink es un personaje de la pel√≠cula \"Wild Robot\". Se presenta como un zorro, un depredador astuto y resbaladizo, y un experto local en gansos.\n",
            "\n",
            "Algunas caracter√≠sticas y acciones clave de Fink incluyen:\n",
            "*   **Naturaleza depredadora y enga√±osa:** Inicialmente, Fink intenta arrebatar un gansito a Rozzum 7134, explicando que es su naturaleza de zorro hacer \"cosas de zorro\". Tambi√©n se muestra manipulador, preguntando si Rozzum 7134 cree todo lo que escucha despu√©s de decir que no se comer√≠a al gansito, para luego retractarse de inmediato.\n",
            "*   **Ayuda al gansito:** A pesar de su naturaleza, Fink ayuda a Rozzum 7134 a cuidar al gansito, ense√±√°ndole a comer, nadar y volar. Sin embargo, sus m√©todos a menudo son ego√≠stas, como cuando se come las vieiras y la miel destinadas al gansito.\n",
            "*   **Comportamiento y personalidad:** Fink es glot√≥n, se le ve comiendo frecuentemente y defendiendo su comida, incluso robando salm√≥n de Thorn. Tambi√©n es territorial, ya que defiende su \"trono\" de una nutria beb√©.\n",
            "*   **Interacciones con otros:** Aunque a menudo expresa desagrado por los dem√°s, Fink ayuda a Rozzum 7134 y a otros animales en situaciones dif√≠ciles. Es un personaje astuto, demostrado en sus intentos de recuperar un huevo de Rozzum 7134.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oip0SClG2MeI"
      },
      "source": [
        "---\n",
        "\n",
        "## 5. üìö Obtener Citaciones\n",
        "\n",
        "Las citaciones te permiten verificar de d√≥nde viene cada parte de la respuesta.\n",
        "\n",
        "### Por qu√© son importantes:\n",
        "- ‚úÖ Verificabilidad y confianza\n",
        "- ‚úÖ Cumplimiento y auditor√≠a\n",
        "- ‚úÖ Debugging de respuestas incorrectas\n",
        "- ‚úÖ Transparencia en aplicaciones cr√≠ticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIyGZI5e2MeJ"
      },
      "outputs": [],
      "source": [
        "def search_with_citations(\n",
        "    query: str,\n",
        "    store_names: List[str],\n",
        "    show_full_chunks: bool = False\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Realiza una b√∫squeda y muestra las citaciones de forma legible.\n",
        "\n",
        "    Args:\n",
        "        query: Pregunta en lenguaje natural\n",
        "        store_names: Lista de stores donde buscar\n",
        "        show_full_chunks: Si True, muestra el texto completo de cada chunk\n",
        "    \"\"\"\n",
        "    print(f\"‚ùì Pregunta: {query}\\n\")\n",
        "\n",
        "    # Realizar b√∫squeda\n",
        "    response = search_file_store(query, store_names)\n",
        "\n",
        "    # Mostrar respuesta\n",
        "    print(f\"üí¨ Respuesta:\\n{response.text}\\n\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Obtener citaciones\n",
        "    grounding = response.candidates[0].grounding_metadata\n",
        "\n",
        "    if not grounding or not grounding.grounding_chunks:\n",
        "        print(\"‚ÑπÔ∏è  No hay citaciones disponibles para esta respuesta\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüìñ CITACIONES ({len(grounding.grounding_chunks)} fuentes):\\n\")\n",
        "\n",
        "    for i, chunk in enumerate(grounding.grounding_chunks, 1):\n",
        "        context = chunk.retrieved_context\n",
        "\n",
        "        print(f\"[{i}] üìÑ Fuente: {context.title}\")\n",
        "\n",
        "        if show_full_chunks:\n",
        "            print(f\"    Contenido:\\n{context.text}\\n\")\n",
        "        else:\n",
        "            # Mostrar solo un extracto\n",
        "            preview = context.text[:200] + \"...\" if len(context.text) > 200 else context.text\n",
        "            print(f\"    Extracto: {preview}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPkiZg8b2MeK",
        "outputId": "c2e4bb67-e805-40c8-9f5c-85433c577f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùì Pregunta: ¬øCu√°les son los l√≠mites de almacenamiento seg√∫n el tier del usuario?\n",
            "\n",
            "üí¨ Respuesta:\n",
            "Los l√≠mites de almacenamiento total para los almacenes de File Search de un proyecto var√≠an seg√∫n el nivel de usuario:\n",
            "\n",
            "*   **Gratuito:** 1 GB\n",
            "*   **Nivel 1:** 10 GB\n",
            "*   **Nivel 2:** 100 GB\n",
            "*   **Nivel 3:** 1 TB\n",
            "\n",
            "Adem√°s, el tama√±o m√°ximo por archivo o por documento est√° limitado a 100 MB. Se recomienda que el tama√±o de cada almac√©n de File Search sea inferior a 20 GB para asegurar latencias √≥ptimas de recuperaci√≥n.\n",
            "\n",
            "Es importante tener en cuenta que el l√≠mite de tama√±o del almac√©n de File Search se calcula en el backend, bas√°ndose en el tama√±o de la entrada m√°s los embeddings generados y almacenados con ella, lo que suele ser aproximadamente 3 veces el tama√±o de los datos de entrada. El almacenamiento en s√≠ no tiene costo.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "üìñ CITACIONES (3 fuentes):\n",
            "\n",
            "[1] üìÑ Fuente: Gu√≠a Completa de File Search\n",
            "    Extracto: text/x-dsrc\n",
            "\n",
            "text/x-emacs-lisp\n",
            "\n",
            "text/x-erlang\n",
            "\n",
            "text/x-gff3\n",
            "\n",
            "text/x-go\n",
            "\n",
            "‚Ä¢ text/x-haskell\n",
            "\n",
            "text/x-java\n",
            "\n",
            "‚Ä¢\n",
            "\n",
            "text/x-java-properties\n",
            "\n",
            "‚Ä¢\n",
            "\n",
            "text/x-java-source\n",
            "\n",
            "text/x-kotlin\n",
            "\n",
            "text/x-lilypond\n",
            "\n",
            "text/x-lisp\n",
            "\n",
            "‚Ä¢ t...\n",
            "\n",
            "[2] üìÑ Fuente: Gu√≠a Completa de File Search\n",
            "    Extracto: charge.\n",
            "\n",
            "‚Ä¢ Query time embeddings are free of charge.\n",
            "\n",
            "Retrieved document tokens are charged as regular context tokens\n",
            " (/gemini-api/docs/tokens).\n",
            "\n",
            "What's next\n",
            "\n",
            "https://ai.google.dev/gemini-api/docs/fi...\n",
            "\n",
            "[3] üìÑ Fuente: Gu√≠a Completa de File Search\n",
            "    Extracto: more search\n",
            "\n",
            "The indexing and querying process of File Search\n",
            "\n",
            "In this diagram, the dotted line from from Documents to Embedding model (using gemini-\n",
            " embedding-001 (/gemini-api/docs/embeddings)) repr...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo: B√∫squeda con citaciones\n",
        "search_with_citations(\n",
        "    query=\"¬øCu√°les son los l√≠mites de almacenamiento seg√∫n el tier del usuario?\",\n",
        "    store_names=[store.name],\n",
        "    show_full_chunks=False  # Cambia a True para ver el texto completo\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vfungLe2MeN"
      },
      "source": [
        "---\n",
        "\n",
        "## 6. üè∑Ô∏è Metadata Filtering Avanzado\n",
        "\n",
        "El metadata filtering te permite hacer b√∫squedas ultra-precisas en subconjuntos de tus documentos.\n",
        "\n",
        "### Sintaxis soportada:\n",
        "- `key = 'value'` - Igualdad exacta\n",
        "- `key != 'value'` - Diferente de\n",
        "- `key > 100` - Mayor que (num√©rico)\n",
        "- `key >= 100` - Mayor o igual\n",
        "- `key < 100` - Menor que\n",
        "- `key <= 100` - Menor o igual\n",
        "- `key IN ['val1', 'val2']` - Uno de varios valores\n",
        "- Combinar con `AND` y `OR`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X4l6R0S2MeN"
      },
      "source": [
        "### Crear documentos con metadata rica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QbvKjnH2MeO",
        "outputId": "c80a47df-35ff-4021-9654-cb23daf68e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Subiendo: pricing_2025.txt...\n",
            "‚è≥ Indexando (esto puede tomar algunos segundos)...\n",
            "‚úÖ Archivo indexado: pricing_2025.txt\n",
            "\n",
            "üì§ Subiendo: features_2024.txt...\n",
            "‚è≥ Indexando (esto puede tomar algunos segundos)...\n",
            "‚úÖ Archivo indexado: features_2024.txt\n",
            "\n",
            "üì§ Subiendo: pricing_2023.txt...\n",
            "‚è≥ Indexando (esto puede tomar algunos segundos)...\n",
            "‚úÖ Archivo indexado: pricing_2023.txt\n",
            "\n",
            "‚úÖ Documentos con metadata subidos\n"
          ]
        }
      ],
      "source": [
        "# Crear varios documentos con diferentes metadata\n",
        "docs_with_metadata = [\n",
        "    {\n",
        "        'filename': 'pricing_2025.txt',\n",
        "        'content': 'Precios 2025: File Search cobra $0.15 por mill√≥n de tokens en indexaci√≥n. Storage es gratuito.',\n",
        "        'metadata': [\n",
        "            {'key': 'anio', 'numeric_value': 2025},\n",
        "            {'key': 'categoria', 'string_value': 'pricing'},\n",
        "            {'key': 'departamento', 'string_value': 'finanzas'}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        'filename': 'features_2024.txt',\n",
        "        'content': 'Caracter√≠sticas 2024: Soporte para PDF, DOCX, TXT, c√≥digo fuente. B√∫squeda sem√°ntica avanzada.',\n",
        "        'metadata': [\n",
        "            {'key': 'anio', 'numeric_value': 2024},\n",
        "            {'key': 'categoria', 'string_value': 'features'},\n",
        "            {'key': 'departamento', 'string_value': 'producto'}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        'filename': 'pricing_2023.txt',\n",
        "        'content': 'Precios 2023: En la versi√≥n anterior era de 0.5$ usd, el pricing era diferente. Versi√≥n legacy.',\n",
        "        'metadata': [\n",
        "            {'key': 'anio', 'numeric_value': 2023},\n",
        "            {'key': 'categoria', 'string_value': 'pricing'},\n",
        "            {'key': 'departamento', 'string_value': 'finanzas'},\n",
        "            {'key': 'legacy', 'string_value': 'true'}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Subir los documentos\n",
        "for doc in docs_with_metadata:\n",
        "    # Crear archivo temporal\n",
        "    with open(doc['filename'], 'w', encoding='utf-8') as f:\n",
        "        f.write(doc['content'])\n",
        "\n",
        "    # Subir con metadata\n",
        "    upload_file_to_store(\n",
        "        file_path=doc['filename'],\n",
        "        store_name=store.name,\n",
        "        display_name=doc['filename'],\n",
        "        custom_metadata=doc['metadata']\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Documentos con metadata subidos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM2sgjbj2MeP"
      },
      "source": [
        "### Ejemplos de filtrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyW6WVQ92MeP",
        "outputId": "29c83dc9-1fad-49f0-f6a5-3675cc377936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Filtro: anio = 2025\n",
            "\n",
            "Respuesta: El precio actual para la indexaci√≥n con File Search es de $0.15 por mill√≥n de tokens. El almacenamiento es gratuito.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Filtro 1: Solo documentos de 2024\n",
        "print(\"üîç Filtro: anio = 2025\\n\")\n",
        "\n",
        "response = search_file_store(\n",
        "    query=\"¬øCu√°l es el precio actual?\",\n",
        "    store_names=[store.name],\n",
        "    metadata_filter=\"anio=2025\"\n",
        ")\n",
        "\n",
        "print(f\"Respuesta: {response.text}\\n\")\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mbOGaUo2MeR",
        "outputId": "c9368527-c384-4c4c-ffcf-441b2f9b998c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Filtro: anio >= 2024\n",
            "\n",
            "Respuesta: Las caracter√≠sticas disponibles para el a√±o 2024 incluyen soporte para diferentes formatos de archivo como PDF, DOCX, TXT y c√≥digo fuente. Tambi√©n se destaca la funcionalidad de b√∫squeda sem√°ntica avanzada.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Filtro 2: Rango de a√±os\n",
        "print(\"üîç Filtro: anio >= 2024\\n\")\n",
        "\n",
        "response = search_file_store(\n",
        "    query=\"Dame la informaci√≥n de Caracter√≠sticas\",\n",
        "    store_names=[store.name],\n",
        "    metadata_filter=\"anio>=2024\"\n",
        ")\n",
        "\n",
        "print(f\"Respuesta: {response.text}\\n\")\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtdmTzD52MeR",
        "outputId": "87352abf-e84b-4568-a6ea-8924848f29c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Filtro: departamento finanzas\n",
            "\n",
            "Respuesta: S√≠, hay informaci√≥n sobre precios para 2023. En la versi√≥n anterior, el precio era de 0.5 USD, y se refiere a una versi√≥n legacy.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Filtro 3: M√∫ltiples categor√≠as con OR\n",
        "print(\"üîç Filtro: departamento finanzas\\n\")\n",
        "\n",
        "response = search_file_store(\n",
        "    query=\"Hay precios para 2023?\",\n",
        "    store_names=[store.name],\n",
        "    metadata_filter=\"departamento=finanzas\"\n",
        ")\n",
        "\n",
        "print(f\"Respuesta: {response.text}\\n\")\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVwvWKM02MeS"
      },
      "source": [
        "---\n",
        "\n",
        "## 7. üóÇÔ∏è Gesti√≥n de Stores\n",
        "\n",
        "Funciones para listar, obtener informaci√≥n, y eliminar stores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSp2laT22MeS",
        "outputId": "d0699cac-e272-47cb-8f54-19cc89860717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìö Tienes 4 store(s):\n",
            "\n",
            "1. Tutorial Gemini File Search - Documentaci√≥n\n",
            "   ‚Ä¢ ID: fileSearchStores/tutorial-gemini-file-search-iklce8ioifrj\n",
            "   ‚Ä¢ Creado: 2025-11-26 14:22:19.165785+00:00\n",
            "\n",
            "2. Script peliculas\n",
            "   ‚Ä¢ ID: fileSearchStores/script-peliculas-ajfi4b7f9nli\n",
            "   ‚Ä¢ Creado: 2025-11-26 14:23:56.660188+00:00\n",
            "\n",
            "3. Script peliculas\n",
            "   ‚Ä¢ ID: fileSearchStores/script-peliculas-4hkv65d8r8vd\n",
            "   ‚Ä¢ Creado: 2025-11-26 14:50:45.579962+00:00\n",
            "\n",
            "4. Tutorial Gemini File Search - Documentaci√≥n\n",
            "   ‚Ä¢ ID: fileSearchStores/tutorial-gemini-file-search-i8e1b0k6d5t7\n",
            "   ‚Ä¢ Creado: 2025-11-26 14:50:46.345975+00:00\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def list_all_stores() -> List[genai.types.FileSearchStore]:\n",
        "    \"\"\"\n",
        "    Lista todos los File Search Stores del usuario.\n",
        "\n",
        "    Returns:\n",
        "        Lista de FileSearchStore objects\n",
        "    \"\"\"\n",
        "    stores = list(client.file_search_stores.list())\n",
        "\n",
        "    print(f\"üìö Tienes {len(stores)} store(s):\\n\")\n",
        "\n",
        "    for i, store in enumerate(stores, 1):\n",
        "        print(f\"{i}. {store.display_name or 'Sin nombre'}\")\n",
        "        print(f\"   ‚Ä¢ ID: {store.name}\")\n",
        "        print(f\"   ‚Ä¢ Creado: {store.create_time}\\n\")\n",
        "\n",
        "    return stores\n",
        "\n",
        "# Listar stores\n",
        "my_stores = list_all_stores()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLHzQKVz2MeW",
        "outputId": "5477f3b0-3742-4c24-db95-054b469d1834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Informaci√≥n del Store:\n",
            "\n",
            "Nombre: Tutorial Gemini File Search - Documentaci√≥n\n",
            "ID: fileSearchStores/tutorial-gemini-file-search-i8e1b0k6d5t7\n",
            "Creado: 2025-11-26 14:50:46.345975+00:00\n",
            "Actualizado: 2025-11-26 14:50:46.345975+00:00\n"
          ]
        }
      ],
      "source": [
        "def get_store_info(store_name: str) -> None:\n",
        "    \"\"\"\n",
        "    Obtiene informaci√≥n detallada de un store espec√≠fico.\n",
        "\n",
        "    Args:\n",
        "        store_name: Nombre completo del store\n",
        "    \"\"\"\n",
        "    try:\n",
        "        store = client.file_search_stores.get(name=store_name)\n",
        "\n",
        "        print(f\"üìä Informaci√≥n del Store:\\n\")\n",
        "        print(f\"Nombre: {store.display_name or 'Sin nombre'}\")\n",
        "        print(f\"ID: {store.name}\")\n",
        "        print(f\"Creado: {store.create_time}\")\n",
        "        print(f\"Actualizado: {store.update_time}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error obteniendo info del store: {str(e)}\")\n",
        "\n",
        "# Ver info del store actual\n",
        "get_store_info(store.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiDpVffJ2MeX",
        "outputId": "bdbff644-e06e-400e-c1ee-402e581abd93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Store eliminado: fileSearchStores/mi-documentacin-tcnica-0uml3wlpg780\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "def delete_store(store_name: str, confirm: bool = False) -> bool:\n",
        "    \"\"\"\n",
        "    Elimina un File Search Store.\n",
        "\n",
        "    ‚ö†Ô∏è ADVERTENCIA: Esta acci√≥n es IRREVERSIBLE.\n",
        "    Se perder√°n todos los documentos indexados.\n",
        "\n",
        "    Args:\n",
        "        store_name: Nombre del store a eliminar\n",
        "        confirm: Debe ser True para confirmar la eliminaci√≥n\n",
        "\n",
        "    Returns:\n",
        "        bool: True si se elimin√≥ exitosamente\n",
        "    \"\"\"\n",
        "    if not confirm:\n",
        "        print(\"‚ö†Ô∏è  ADVERTENCIA: Debes pasar confirm=True para eliminar el store\")\n",
        "        print(\"   Esta acci√≥n es IRREVERSIBLE y eliminar√° todos los documentos indexados.\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        client.file_search_stores.delete(name=store_name, config={'force': True})\n",
        "        print(f\"‚úÖ Store eliminado: {store_name}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error eliminando store: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Ejemplo (comentado por seguridad)\n",
        "delete_store('fileSearchStores/mi-documentacin-tcnica-0uml3wlpg780', confirm=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUI7nMHU2MeX"
      },
      "source": [
        "---\n",
        "\n",
        "## 8. ‚öôÔ∏è Chunking Personalizado\n",
        "\n",
        "Por defecto, File Search usa chunking autom√°tico inteligente. Pero puedes personalizarlo si necesitas control espec√≠fico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzzeES9b2MeY"
      },
      "outputs": [],
      "source": [
        "def upload_with_custom_chunking(\n",
        "    file_path: str,\n",
        "    store_name: str,\n",
        "    max_tokens_per_chunk: int = 500,\n",
        "    max_overlap_tokens: int = 50\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Sube un archivo con configuraci√≥n personalizada de chunking.\n",
        "\n",
        "    Args:\n",
        "        file_path: Ruta al archivo\n",
        "        store_name: Nombre del store\n",
        "        max_tokens_per_chunk: M√°ximo de tokens por chunk (default: 500)\n",
        "        max_overlap_tokens: Tokens de overlap entre chunks (default: 50)\n",
        "\n",
        "    Returns:\n",
        "        bool: True si fue exitoso\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üì§ Subiendo con chunking personalizado:\")\n",
        "        print(f\"   ‚Ä¢ Max tokens por chunk: {max_tokens_per_chunk}\")\n",
        "        print(f\"   ‚Ä¢ Overlap: {max_overlap_tokens} tokens\\n\")\n",
        "\n",
        "        operation = client.file_search_stores.upload_to_file_search_store(\n",
        "            file=file_path,\n",
        "            file_search_store_name=store_name,\n",
        "            config={\n",
        "                'display_name': file_path,\n",
        "                'chunking_config': {\n",
        "                    'white_space_config': {\n",
        "                        'max_tokens_per_chunk': max_tokens_per_chunk,\n",
        "                        'max_overlap_tokens': max_overlap_tokens\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Esperar indexaci√≥n\n",
        "        while not operation.done:\n",
        "            time.sleep(5)\n",
        "            operation = client.operations.get(operation)\n",
        "\n",
        "        print(f\"‚úÖ Archivo indexado con chunking personalizado\\n\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {str(e)}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th8DsjhY2MeZ",
        "outputId": "bee21d6b-58f6-4e18-ead6-e4a7fcb7fce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Subiendo con chunking personalizado:\n",
            "   ‚Ä¢ Max tokens por chunk: 200\n",
            "   ‚Ä¢ Overlap: 40 tokens\n",
            "\n",
            "‚úÖ Archivo indexado con chunking personalizado\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Crear documento de prueba con texto largo\n",
        "long_content = \"\"\"\n",
        "Chunking en RAG: Gu√≠a Completa\n",
        "\n",
        "El chunking es el proceso de dividir documentos largos en segmentos m√°s peque√±os.\n",
        "Esto es crucial porque los modelos tienen l√≠mites de contexto y necesitamos\n",
        "recuperar solo la informaci√≥n relevante.\n",
        "\n",
        "Estrategias de Chunking:\n",
        "\n",
        "1. Fixed-size chunking: Dividir por n√∫mero fijo de tokens o caracteres.\n",
        "   Ventajas: Simple de implementar.\n",
        "   Desventajas: Puede cortar contexto importante.\n",
        "\n",
        "2. Semantic chunking: Dividir por significado sem√°ntico.\n",
        "   Ventajas: Mantiene contexto coherente.\n",
        "   Desventajas: M√°s complejo de implementar.\n",
        "\n",
        "3. Recursive chunking: Dividir jer√°rquicamente (p√°rrafos, oraciones, etc.).\n",
        "   Ventajas: Balancea tama√±o y coherencia.\n",
        "   Desventajas: Requiere an√°lisis estructural.\n",
        "\n",
        "File Search usa una combinaci√≥n de estas estrategias autom√°ticamente.\n",
        "\n",
        "El overlap entre chunks es importante para:\n",
        "- No perder contexto en los bordes\n",
        "- Mejorar recuperaci√≥n de informaci√≥n fragmentada\n",
        "- Aumentar recall en b√∫squedas\n",
        "\n",
        "Un buen overlap t√≠pico es 10-20% del tama√±o del chunk.\n",
        "\"\"\" * 3  # Repetir para hacer el documento m√°s largo\n",
        "\n",
        "with open('chunking_guide.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(long_content)\n",
        "\n",
        "# Subir con chunking personalizado\n",
        "upload_with_custom_chunking(\n",
        "    file_path='chunking_guide.txt',\n",
        "    store_name=store.name,\n",
        "    max_tokens_per_chunk=200,  # Chunks m√°s peque√±os\n",
        "    max_overlap_tokens=40      # 20% de overlap\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3L47UPu2Meg"
      },
      "source": [
        "---\n",
        "\n",
        "## 9. üí° Mejores Pr√°cticas\n",
        "\n",
        "### ‚úÖ DO's (Hazlo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMS4y5a-2Meg"
      },
      "source": [
        "```python\n",
        "# ‚úÖ Organizar stores por tipo de contenido\n",
        "docs_publicas = create_file_search_store(\"Documentaci√≥n P√∫blica\")\n",
        "docs_internas = create_file_search_store(\"Documentaci√≥n Interna\")\n",
        "training_data = create_file_search_store(\"Datos de Entrenamiento\")\n",
        "\n",
        "# ‚úÖ Usar metadata rica para filtrado preciso\n",
        "metadata = [\n",
        "    {'key': 'departamento', 'string_value': 'ingenieria'},\n",
        "    {'key': 'fecha', 'numeric_value': 20240101},\n",
        "    {'key': 'confidencial', 'string_value': 'no'},\n",
        "    {'key': 'version', 'numeric_value': 2}\n",
        "]\n",
        "\n",
        "# ‚úÖ Manejar errores apropiadamente\n",
        "try:\n",
        "    response = search_file_store(query, [store.name])\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error en b√∫squeda: {e}\")\n",
        "    # Fallback o retry logic\n",
        "\n",
        "# ‚úÖ Validar citaciones en aplicaciones cr√≠ticas\n",
        "if not response.candidates[0].grounding_metadata:\n",
        "    print(\"‚ö†Ô∏è Respuesta sin citaciones - validar manualmente\")\n",
        "\n",
        "# ‚úÖ Usar display_names descriptivos\n",
        "upload_file_to_store(\n",
        "    file='doc.pdf',\n",
        "    store_name=store.name,\n",
        "    display_name='API Documentation v2.3 - Authentication Module'\n",
        ")\n",
        "\n",
        "# ‚úÖ Implementar rate limiting en producci√≥n\n",
        "import time\n",
        "from functools import wraps\n",
        "\n",
        "def rate_limit(calls_per_minute=10):\n",
        "    def decorator(func):\n",
        "        last_calls = []\n",
        "        \n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            now = time.time()\n",
        "            last_calls[:] = [t for t in last_calls if now - t < 60]\n",
        "            \n",
        "            if len(last_calls) >= calls_per_minute:\n",
        "                sleep_time = 60 - (now - last_calls[0])\n",
        "                time.sleep(sleep_time)\n",
        "            \n",
        "            last_calls.append(time.time())\n",
        "            return func(*args, **kwargs)\n",
        "        \n",
        "        return wrapper\n",
        "    return decorator\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYOR_8yX2Meh"
      },
      "source": [
        "### ‚ùå DON'Ts (No lo hagas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXU_AN0o2Meh"
      },
      "source": [
        "```python\n",
        "# ‚ùå NO subir archivos sin esperar a que la indexaci√≥n complete\n",
        "operation = client.file_search_stores.upload_to_file_search_store(...)\n",
        "# Falta el while loop para esperar\n",
        "search_file_store(query, [store.name])  # Puede fallar!\n",
        "\n",
        "# ‚ùå NO poner credenciales hardcoded\n",
        "API_KEY = 'AIzaSyXXXXXXXX'  # Nunca hagas esto!\n",
        "\n",
        "# ‚úÖ Usa variables de entorno\n",
        "API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "# ‚ùå NO ignorar los l√≠mites de tama√±o\n",
        "# Archivo de 150MB - excede el l√≠mite de 100MB\n",
        "upload_file_to_store('huge_file.pdf', store.name)  # Fallar√°!\n",
        "\n",
        "# ‚úÖ Verificar tama√±o antes de subir\n",
        "import os\n",
        "file_size_mb = os.path.getsize('file.pdf') / (1024 * 1024)\n",
        "if file_size_mb > 100:\n",
        "    print(\"Archivo muy grande - considerar dividir\")\n",
        "\n",
        "# ‚ùå NO usar modelos no soportados\n",
        "search_file_store(\n",
        "    query=\"test\",\n",
        "    store_names=[store.name],\n",
        "    model='gemini-1.5-pro'  # No soportado!\n",
        ")\n",
        "\n",
        "# ‚úÖ Usar solo modelos soportados\n",
        "supported_models = ['gemini-2.5-flash', 'gemini-2.5-pro']\n",
        "\n",
        "# ‚ùå NO asumir que siempre hay citaciones\n",
        "sources = response.candidates[0].grounding_metadata.grounding_chunks[0]  # Puede ser None!\n",
        "\n",
        "# ‚úÖ Verificar primero\n",
        "grounding = response.candidates[0].grounding_metadata\n",
        "if grounding and grounding.grounding_chunks:\n",
        "    sources = grounding.grounding_chunks\n",
        "\n",
        "# ‚ùå NO crear un store gigante con todo\n",
        "mega_store = create_file_search_store(\"Todo\")\n",
        "# Sube docs p√∫blicos, internos, c√≥digo, etc. todo junto - mala pr√°ctica!\n",
        "\n",
        "# ‚úÖ Separar por contexto y seguridad\n",
        "public_store = create_file_search_store(\"P√∫blico\")\n",
        "private_store = create_file_search_store(\"Interno\")\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}